
* One-LLM-API: Unified AI Chat Completion Endpoint

One-LLM-API is a Cloudflare worker that simplifies accessing multiple AI model services by providing a single ~chat/completion~ API endpoint, with logging and monitoring capabilities. Service providers supported include OpenAI, Azure OpenAI, Claude, and Google Palm.

** Key Features

- Unified API endpoint for multiple AI chat completion services
- Chat to *Multiple Models* on a single request;
- Simplified authentication utilizing a single API key
- Logging and monitoring support for enhanced observability
- Observability based on [[https://developers.cloudflare.com/analytics/analytics-engine/][Workers Analytics Engine (beta)]]
- Support for OpenAI, Azure OpenAI, Claude, and Google Palm;
- Support multiple resource config for Azure OpenAI;

*** Features may be added in the future
1. Distribute "ONELLM_API_KEY" for differnt users;
2. Throttling;
3. A cost analytics page;

** Quick Start

#+begin_src sh :exports both :wrap src sh :results raw replace
curl https://api.1lm.workers.dev ... // TODO
#+end_src


** Usages

To use the adapter, simply make requests to the worker endpoint with the OpenAI
JSON request payload.

Behind the scenes the worker will:

- Route requests to the appropriate backend based on the `model` specified
- Transform request payload to the destination API format
- Proxy the request and response
- Convert responses back to OpenAI format


*** Request Example

For example, to use =gpt-3.5-turbo=:

#+begin_src json :exports both
{
	"model": "gpt-3.5-turbo",
	"stream": true,
	"messages": [
		{
			"role": "user",
			"content": "Hello there!"
		}
	]
}
#+end_src

To use =claude-2=:

#+begin_src json :exports both
{
	"model": "claude-2",
	"stream": true,
	"messages": [...]
}
#+end_src


You can specify *multiple models* (delimitered by ~,~) to query in parallel:

#+begin_src json :exports both
{
	"model": "gpt-3.5-turbo,claude-2",
	"stream": true,
	"messages": [...]
}
#+end_src

The response will contain the concatenated output from both models streamed in
the OpenAI API format.

Other OpenAI parameters like `temperature`, `stream`, `stop` etc. can also be
specified normally.

*** Python Example

#+begin_src python :exports both :results output
import openai

openai.api_key = "<your specified API_KEY>"
openai.api_base = "<your worker endpoint>/v1"

# For example, the local wrangler development endpoint
# openai.api_key = 'sk-fakekey'
# openai.api_base = "http://127.0.0.1:8787/v1"

chat_completion = openai.ChatCompletion.create(
    model="gpt-4,claude-2",
    messages=[
        {
            "role": "user",
            "content": "A brief introduction about yourself and say hello!",
        }
    ],
    stream=True,
)


for chunk in chat_completion:
    if chunk["choices"]:
        print(chunk["model"], chunk["choices"][0]["delta"].get("content", ""))
#+end_src

** The API Services supported [2/4]

*** [X] OpenAI
CLOSED: [2023-07-18 Tue 21:08]
*** [X] Azure OpenAI
CLOSED: [2023-07-18 Tue 21:09]
*** [ ] Claude
CLOSED: [2023-07-18 Tue 21:09]
*** [ ] Google Palm
CLOSED: [2023-07-18 Tue 21:09]

** The /models/ suported

Here are the models currently supported by the adapter service:

To use a particular model, specify its ID in the `model` field of the request body.

*** OpenAI Models

All the chat models available by your OPENAI_API_KEY

*** Azure OpenAI Models

Based on your deployment name, you will have to set the environment variable
~AZURE_OPENAI_API_KEY~ to the corresponding API key.

You can also setup multiple deployments with different API keys to access
different models.

// TODO:

*** TODO Claude Models
:LOGBOOK:
- State "TODO"       from              [2023-09-04 Mon 23:24]
:END:

- claude-instant-1(claude-instant-1.2)
- claude-2(claude-2.0)

*** TODO Google Palm Models
:LOGBOOK:
- State "TODO"       from              [2023-09-04 Mon 23:24]
:END:

- text-bison-001
- chat-bison-001

** Deployment


[[https://deploy.workers.cloudflare.com/?url=https://github.com/lroolle/one-llm-api][Deploy to Cloudflare Workers]]


To deploy, you will need:

- Cloudflare account
- API keys for each service

*** Install wrangler

#+begin_src sh :exports both :wrap src sh :results raw replace
npm i wrangler -g
#+end_src

*** KV create
#+begin_src sh :exports both :wrap src sh :results raw replace
wrangler kv:namespace create ONELLM_KV

# if you need to test in the local wrangler dev
wrangler kv:namespace create ONELLM_KV --preview
#+end_src

*** Environment Variables

Configure the worker environment variables with your secret keys.

Skip the service key if you do not have one or you do not want to deploy it.

#+begin_src sh :exports both :wrap src sh :results raw replace
wrangler secret put ONELLM_API_KEY
wrangler secret put OPENAI_API_KEY
wrangler secret put AZURE_OPENAI_API_KEYS
wrangler secret put ANTHROPIC_API_KEY
wrangler secret put PALM_API_KEY
#+end_src

Or you can add the keys after deploy using the Cloudflare dashboard.

#+begin_quote
Worker -> Settings -> Variables -> Environment Variables
#+end_quote

*** Run publish/deploy

#+begin_src sh :exports both :wrap src sh :results raw replace
wrangler depoly
#+end_src
** TODO Run with workerd
:LOGBOOK:
- State "TODO"       from              [2023-09-10 Sun 14:04]
:END:

*** Dockered

** Development

Create a ~.dev.vars~ with your environment API_KEYs, then run:

#+begin_src sh :exports both :wrap src sh :results raw replace
wrangler dev
#+end_src


#+begin_src sh :exports both :wrap src sh :results raw replace
curl -vvv http://127.0.0.1:8787/v1/chat/completions -H "Content-Type: application/json" -H "Authorization: Bearer sk-fakekey" -d '{
    "model": "gpt-3.5-turbo,claude-2", "stream": true,
    "messages": [{"role": "user", "content": "Say: Hello I am your helpful one Assistant."}]
  }'
#+end_src

** Alternatives

1. Workerjs like [[https://github.com/haibbo/cf-openai-azure-proxy][haibbo/cf-openai-azure-proxy]]
   This project draws inspiration from, and is based on the work of [[https://github.com/haibbo/cf-openai-azure-proxy][haibbo/cf-openai-azure-proxy]]. If you only require a single service proxy(such as Claude/Azure), please consider using this one.
2. https://helicone.ai
   Helicone is an open-source observability platform for Language Learning Models (LLMs).
3. https://llm.report
   ðŸ“Š llm.report is an open-source logging and analytics platform for OpenAI: Log your ChatGPT API requests, analyze costs, and improve your prompts.

** Contributions

Contributions and improvements are welcome! Please open GitHub issues or PRs.

Let me know if you would like any changes or have additional sections to add!

** License

ONE-LLM-API is licensed under the [[./LICENSE][Appache 2.0 License]].


* README Meta

#+begin_ai markdown :model gpt-4-0314 :temperature 1.0
[SYS]: We're working on a project named one-llm-api(1lm.io), with key features like:
- *One chat completion endpoint to access multiple AI Model services*;
- Chat to *Multiple Models* on a single request;
- One API key for authentication;
- Support for OpenAI, Azure OpenAI, Claude, and Google Palm;
- Support multiple resource config for Azure OpenAI;
- Observability based on [[https://developers.cloudflare.com/analytics/analytics-engine/][Workers Analytics Engine (beta)]]
- Features may be added in the future
  - Multiple "ONELLM_API_KEY" distribution support;
  - Track costs;
  - Throttling(Rate Limiting by API keys);

[ME]: If you're an SEO expert, what suggestions you may give on the domain name 1lm.io?



[AI]: As an SEO expert, I would recommend considering the following suggestions for your domain name 1lm.io:

1. Consider a more descriptive domain name: Short domain names like 1lm.io can be catchy but may not convey what your service does. Consider using a longer, more descriptive domain name that includes relevant keywords or phrases related to your project (e.g. ai-multimodel-api.com).

2. Use a .com domain if possible: While .io domains have become popular, especially among tech startups, .com domains are still the most recognized and trusted TLDs. If possible, consider acquiring a .com version of your domain to improve trust and visibility.

3. Branding: Ensure that the domain name is unique, memorable, and reflects your project's branding. This will help users associate the domain name with your project and make it easier for them to find it in search results.

4. Optimize for searchability: Include relevant keywords in your domain name that target the services or technology your project provides. This can help improve your organic search rankings and make it easier for users to find you online.

5. Avoid using non-alphanumeric characters: Although numbers (like "1") and special characters (like "-") are allowed in domain names, they can make it harder for users to remember and type out your domain. Stick with letters to make your domain more user-friendly.

6. Research potential trademark or copyright issues: Before committing to a domain name, make sure it doesn't infringe on any existing trademarks or copyrights to avoid legal issues down the road.

7. Monitor your online reputation: Once you've chosen a domain name, keep track of your online reputation, reviews, and search engine rankings to ensure you're maintaining a positive image and continually optimizing your online presence.

Regardless of which domain name you choose, the most important factor for SEO is creating high-quality, relevant content and providing excellent user experience on your website. Focus on these areas to ensure your website ranks well in search results and attracts visitors.

[ME]: Okay, I'm writing the README.md for this project, help with improve it:

Requesting a single API endpoint, with logging and monitoring.

This is a Cloudflare worker that acts as an adapter to proxy requests to the [[https://platform.openai.com/docs/guides/gpt/chat-completions-api][OpenAI Chat Completions API]] to other AI services like Claude, Azure OpenAI, and Google Palm.


[AI]: # One-LLM-API: Unified AI Chat Completion Endpoint

One-LLM-API is a Cloudflare worker that simplifies accessing multiple AI chat completion services by providing a single API endpoint. This solution is designed to streamline the integration and management of AI services such as OpenAI, Claude, Azure OpenAI, and Google Palm, while offering logging and monitoring capabilities.

## Features

- Unified API endpoint for multiple AI chat completion services
- Seamless proxy for requests to OpenAI Chat Completions API and other AI services, including Claude, Azure OpenAI, and Google Palm
- Built with Cloudflare Workers for optimized performance and reliability
- Logging and monitoring support for enhanced observability
- Simplified authentication utilizing a single API key
- Frequent updates and feature additions to support evolving AI technology

## Getting Started
...


[ME]:
#+end_ai
